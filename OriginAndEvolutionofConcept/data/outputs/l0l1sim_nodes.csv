id,similarity,label
07ff62cd1432440eae1778810c1f29536fcbbc94,0.16289049968656602,Learning Unambiguous Reduced Sequence Descriptions
fd0da2f1d2b95e5b62221a00ff132219d0c853b7,0.10760683586791174,Adaptive neural oscillator using continuous-time back-propagation learning
9b7861d28f653ead3e02f1ae5c07540b2d07346d,0.052420423974732844,Contrastive Learning and Neural Oscillations
e141d68065ce638f9fc4f006eab2f66711e89768,0.16084216671934048,Induction of Multiscale Temporal Structure
415dca031402b5186c0c8bf00ca7bb60bfedb986,0.04225038247352797,Language Induction by Phase Transition in Dynamical Recognizers
c75646b4c7c2be3146d4100faa9709e87b566a29,0.09313500020051428,Learning Sequential Tasks by Incrementally Adding Higher Orders
26bc0449360d7016f684eafae5b5d2feded32041,0.17034983772359844,An efficient gradient-based algorithm for on-line training of recurrent network trajectories
34f8c5769899dfd9450bb13c3f52c18c88444515,0.09748048374987783,Experimental Comparison of the Effect of Order in Recurrent Neural Networks
ba18247cd3ce9f711eecc7296f1c3561dbfb6cc2,0.15840222388105513,Learning long-term dependencies with gradient descent is difficult
13369d124474b5f8dcbc70d12296a185832192b2,0.09067893082249052,Credit Assignment through Time: Alternatives to Backpropagation
43fc4bacab585ee771bbb885afdc164286c6f020,0.314322248404688,LSTM can Solve Hard Long Time Lag Problems
ca7c44df33389ad1dfd81b3fac1aa9176bd4b386,0.13213152521927582,Generalization of backpropagation with application to a recurrent gas market model
b1ae0fb208fd389d2ff723e5442f9ca7896cb0a4,0.1031456495061769,Time Warping Invariant Neural Networks
02edd775274032afa9fd0420386d38ba3a58c18a,0.1489232618662868,Learning state space trajectories in recurrent neural networks
107ef9cef29c6def0e6c8eea39fe9c0bf726f35f,0.13656081273156567,Gradient calculations for dynamic recurrent neural networks: a survey
e1f9ae1751c8727e77d5ead933c4611d824349ea,0.06300286982597851,A time-delay neural network architecture for isolated word recognition
c61d139a2382760f560164e25e4be264de5dd59f,0.18840750783290816,"Learning Complex, Extended Sequences Using the Principle of History Compression"
a64ca771a733d58dcbf8f7a3fe65a09310424bf8,0.03170121612011939,Induction of Finite-State Languages Using Second-Order Recurrent Networks
f62c3868ebabb5d84bfcf1c5eae6d72d5fb33125,0.10861905775187404,Learning long-term dependencies in NARX recurrent neural networks
0b3cfbf79d50dae4a16584533227bb728e3522aa,0.9999999999999999,Long Short-Term Memory
